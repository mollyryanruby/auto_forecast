{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to run notebook inside of package\n",
    "import sys\n",
    "sys.path.append('/Users/mollyliebeskind/Documents/auto_forecast/auto_forecast')\n",
    "\n",
    "# standard data manipulation imports\n",
    "import pandas as pd\n",
    "\n",
    "# import internal package functions\n",
    "from src.plotting import *\n",
    "from src.data_processing import *\n",
    "from src.modeling import RegressionModel\n",
    "\n",
    "# import modeling functions\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "DTypePromotionError",
     "evalue": "The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Float64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDTypePromotionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m train, test \u001b[39m=\u001b[39m create_train_test(supervised_data, forecast_horizon)\n\u001b[1;32m     32\u001b[0m scaler \u001b[39m=\u001b[39m DataScaler()\n\u001b[0;32m---> 33\u001b[0m train \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mfit_transform(train)\n\u001b[1;32m     34\u001b[0m test \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(test)\n\u001b[1;32m     36\u001b[0m \u001b[39m# rm = RegressionModel(supervised_data, x_cols, diffed_value_col, forecast_horizon)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39m# train, test = rm.create_train_test()\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39m# train_scaled, test_scaled, scaler = rm.min_max_built_in_scaler()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m \n\u001b[1;32m     44\u001b[0m \u001b[39m# rm.models\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/auto_forecast/auto_forecast/src/data_processing.py:64\u001b[0m, in \u001b[0;36mDataScaler.fit_transform\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[0;32m---> 64\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(data)\n\u001b[1;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(data)\n",
      "File \u001b[0;32m~/Documents/auto_forecast/auto_forecast/src/data_processing.py:54\u001b[0m, in \u001b[0;36mDataScaler.fit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[1;32m     53\u001b[0m     scaler \u001b[39m=\u001b[39m MinMaxScaler(feature_range\u001b[39m=\u001b[39m(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mfit(data)\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/auto-forecasting/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:427\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 427\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/auto-forecasting/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:466\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    461\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMinMaxScaler does not support sparse input. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    462\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConsider using MaxAbsScaler instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    463\u001b[0m     )\n\u001b[1;32m    465\u001b[0m first_pass \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 466\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    467\u001b[0m     X,\n\u001b[1;32m    468\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_pass,\n\u001b[1;32m    469\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[1;32m    470\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    471\u001b[0m )\n\u001b[1;32m    473\u001b[0m data_min \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmin(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    474\u001b[0m data_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmax(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/auto-forecasting/lib/python3.11/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 565\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/auto-forecasting/lib/python3.11/site-packages/sklearn/utils/validation.py:778\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    774\u001b[0m     pandas_requires_conversion \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(\n\u001b[1;32m    775\u001b[0m         _pandas_dtype_needs_early_conversion(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m dtypes_orig\n\u001b[1;32m    776\u001b[0m     )\n\u001b[1;32m    777\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(dtype_iter, np\u001b[39m.\u001b[39mdtype) \u001b[39mfor\u001b[39;00m dtype_iter \u001b[39min\u001b[39;00m dtypes_orig):\n\u001b[0;32m--> 778\u001b[0m         dtype_orig \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mresult_type(\u001b[39m*\u001b[39;49mdtypes_orig)\n\u001b[1;32m    780\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(array, \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(array, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    781\u001b[0m     \u001b[39m# array is a pandas series\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     pandas_requires_conversion \u001b[39m=\u001b[39m _pandas_dtype_needs_early_conversion(array\u001b[39m.\u001b[39mdtype)\n",
      "\u001b[0;31mDTypePromotionError\u001b[0m: The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Float64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>)"
     ]
    }
   ],
   "source": [
    "value_col = 'sales'\n",
    "diffed_value_col = f\"{value_col}_differenced\"\n",
    "date_col = 'date'\n",
    "mean_freq = 'Y'\n",
    "daily_data = pd.read_csv('train.csv')\n",
    "forecast_horizon = 12\n",
    "\n",
    "monthly_data = aggregate_by_time(\n",
    "    daily_data, \n",
    "    date_col, \n",
    "    resample_freq='M', \n",
    "    aggregate='sum'\n",
    "    )\n",
    "\n",
    "monthly_data = difference_data(\n",
    "    data=monthly_data, \n",
    "    date_col=date_col,\n",
    "    value_col=value_col, \n",
    "    diff_value_col_name=diffed_value_col\n",
    "    )\n",
    "\n",
    "supervised_data = create_lag_data(\n",
    "    data=monthly_data, \n",
    "    date_col=date_col, \n",
    "    value_col=diffed_value_col, \n",
    "    lags=13)\n",
    "\n",
    "# train, test = create_train_test(supervised_data, test_size)\n",
    "\n",
    "x_cols = list(supervised_data.drop(['store', 'item', date_col, value_col, diffed_value_col], axis=1).columns)\n",
    "train, test = create_train_test(supervised_data, forecast_horizon)\n",
    "scaler = DataScaler()\n",
    "train = scaler.fit_transform(train)\n",
    "test = scaler.transform(test)\n",
    "\n",
    "# rm = RegressionModel(supervised_data, x_cols, diffed_value_col, forecast_horizon)\n",
    "# train, test = rm.create_train_test()\n",
    "# train_scaled, test_scaled, scaler = rm.min_max_built_in_scaler()\n",
    "# X_train_scaled, y_train_scaled, X_test_scaled, y_test_scaled = rm.get_train_test_x_y(scaled=True)\n",
    "# rm.fit(LinearRegression(), 'LinearRegression')\n",
    "# lin_reg_pred = rm.predict('LinearRegression', X_test_scaled, y_values=y_test_scaled)\n",
    "\n",
    "\n",
    "# rm.models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_periodic_values_hist(daily_data, value_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_values_per_group(daily_data, value_col, ['store'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_series(monthly_data, date_col, value_col, mean_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_series(monthly_data, date_col, diffed_value_col, mean_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_acf_pcf(monthly_data, date_col, diffed_value_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_lag_cols(supervised_data, date_col, diffed_value_col, 'lag', num_lags=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_train_test(train, test, date_col, diffed_value_col, figsize=(12,4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto-forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
